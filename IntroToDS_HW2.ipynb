{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "# from pandas.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    names = ['COLLEGE', 'INCOME', 'OVERAGE', 'LEFTOVER', 'HOUSE', 'HANDSET_PRICE',\n",
    "            'OVER_15MINS_CALLS_PER_MONTH', 'AVERAGE_CALL_DURATION', 'REPORTED_SATISFACTION',\n",
    "            'REPORTED_USAGE_LEVEL','CONSIDERING_CHANGE_OF_PLAN','LEAVE']\n",
    "\n",
    "    train_df = pd.read_csv('train.csv', delimiter=',')\n",
    "    test_df = pd.read_csv('test.csv', delimiter=',')\n",
    "    combine = [train_df, test_df]\n",
    "    # train_df = train_df.drop(['COLLEGE', 'AVERAGE_CALL_DURATION', 'OVER_15MINS_CALLS_PER_MONTH', ], axis=1)\n",
    "    # train_df = train_df.drop([ 'COLLEGE', 'REPORTED_USAGE_LEVEL', 'CONSIDERING_CHANGE_OF_PLAN', 'REPORTED_SATISFACTION'], axis=1)\n",
    "\n",
    "    for dataset in combine:\n",
    "        dataset['COLLEGE'] = dataset['COLLEGE'].map( {'one': 1, 'zero': 0} ).astype(int)\n",
    "        dataset['REPORTED_SATISFACTION'] = dataset['REPORTED_SATISFACTION'].map( {'very_unsat': 1, 'unsat': 2, 'avg' : 3, 'sat' : 4, 'very_sat' : 5} ).astype(int)\n",
    "        dataset['REPORTED_USAGE_LEVEL'] = dataset['REPORTED_USAGE_LEVEL'].map( {'very_little': 1, 'little': 2, 'avg' : 3, 'high' :4, 'very_high' :5} ).astype(int)\n",
    "        dataset['CONSIDERING_CHANGE_OF_PLAN'] = dataset['CONSIDERING_CHANGE_OF_PLAN'].map( {'no': 1, 'never_thought': 2, 'perhaps':3, 'considering': 4, 'actively_looking_into_it': 5} ).astype(int)\n",
    "\n",
    "    # train_df['SURVEY'] = train_df['REPORTED_SATISFACTION'] * train_df['REPORTED_USAGE_LEVEL'] * train_df['CONSIDERING_CHANGE_OF_PLAN']\n",
    "    #\n",
    "    #\n",
    "    # # pd.crosstab([data.Sex,data.Survived],data.Pclass,margins=True).style.background_gradient(cmap='summer_r')\n",
    "    #\n",
    "    # # print(train_df[['SURVEY', 'LEAVE']].groupby(['SURVEY'], as_index= False).mean().sort_values(by='LEAVE', ascending=False))\n",
    "    # train_df['INCOME'] = pd.qcut(train_df['INCOME'], 4, labels = [1, 2, 3, 4])\n",
    "    # print(train_df[['INCOME', 'LEAVE']].groupby(['INCOME'], as_index=False).mean().sort_values(by='INCOME', ascending=True))\n",
    "    #\n",
    "    # train_df['HOUSE'] = pd.qcut(train_df['HOUSE'], 4, labels = [1, 2, 3, 4])\n",
    "    # print(train_df[['HOUSE', 'LEAVE']].groupby(['HOUSE'], as_index=False).mean().sort_values(by='HOUSE', ascending=True))\n",
    "    #\n",
    "    # train_df['HANDSET_PRICE'] = pd.cut(train_df['HANDSET_PRICE'], 2, labels = [1, 2])\n",
    "    # print(train_df[['HANDSET_PRICE', 'LEAVE']].groupby(['HANDSET_PRICE'], as_index=False).mean().sort_values(by='HANDSET_PRICE', ascending=True))\n",
    "    # #\n",
    "    # # train_df['AVERAGE_CALL_DURATION'] = pd.qcut(train_df['AVERAGE_CALL_DURATION'], 3, labels = [1, 2, 3])\n",
    "    # # print(train_df[['AVERAGE_CALL_DURATION', 'LEAVE']].groupby(['AVERAGE_CALL_DURATION'], as_index=False).mean().sort_values(by='AVERAGE_CALL_DURATION', ascending=True))\n",
    "    # #\n",
    "    # # train_df['OVER_15MINS_CALLS_PER_MONTH'] = pd.qcut(train_df['OVER_15MINS_CALLS_PER_MONTH'], 3, labels = [1, 2, 3])\n",
    "    # # print(train_df[['OVER_15MINS_CALLS_PER_MONTH', 'LEAVE']].groupby(['OVER_15MINS_CALLS_PER_MONTH'], as_index=False).mean().sort_values(by='OVER_15MINS_CALLS_PER_MONTH', ascending=True))\n",
    "    # #\n",
    "    # #\n",
    "    # # # train_df['OVERAGE'] = pd.qcut(train_df['OVERAGE'], 5)\n",
    "    # # # print(train_df[['OVERAGE', 'LEAVE']].groupby(['OVERAGE'], as_index=False).mean().sort_values(by='OVERAGE', ascending=True))\n",
    "    # #\n",
    "    # train_df['OVERAGE'] = pd.cut(train_df['OVERAGE'], 4, labels = [1, 2, 3, 4])\n",
    "    # print(train_df[['OVERAGE', 'LEAVE']].groupby(['OVERAGE'], as_index=False).mean().sort_values(by='OVERAGE', ascending=True))\n",
    "    #\n",
    "    #\n",
    "    # train_df['LEFTOVER'] = pd.cut(train_df['LEFTOVER'], 4, labels = [1, 2 ,3,4])\n",
    "    # print(train_df[['LEFTOVER', 'LEAVE']].groupby(['LEFTOVER'], as_index=False).mean().sort_values(by='LEFTOVER', ascending=True))\n",
    "    #\n",
    "    #\n",
    "    # train_df['WEALTH'] = train_df['HOUSE'] +  2 * train_df['INCOME']\n",
    "    #\n",
    "    # train_df['WEALTH'] = pd.qcut(train_df['WEALTH'], 4 , labels = [1, 2, 3, 4])\n",
    "    #\n",
    "\n",
    "\n",
    "    train_df = train_df.drop([ 'COLLEGE', \"REPORTED_SATISFACTION\", \"REPORTED_USAGE_LEVEL\" ,\"CONSIDERING_CHANGE_OF_PLAN\" ,'OVER_15MINS_CALLS_PER_MONTH', 'AVERAGE_CALL_DURATION'], axis=1)\n",
    "    # print(train_df[['WEALTH', 'LEAVE']].groupby(['WEALTH'], as_index=False).mean().sort_values(by='WEALTH', ascending=True))\n",
    "\n",
    "    # # print(train_df.head())\n",
    "    X = train_df.drop(\"LEAVE\", axis=1)\n",
    "    y = train_df[\"LEAVE\"]\n",
    "    y = y.astype('int')\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size =1800, random_state=10)\n",
    "    # # X_train, X_test = feature_normalization(X_train, X_test)\n",
    "    # scaler = preprocessing.MinMaxScaler()\n",
    "    # scaler.fit_transform(X_train)\n",
    "    # scaler.fit_transform(X_test)\n",
    "    #\n",
    "\n",
    "\n",
    "    random_forest = RandomForestClassifier(n_estimators=150)\n",
    "    random_forest .fit(X_train, y_train)\n",
    "    acc_random_forest = random_forest.score(X_test, y_test) * 100\n",
    "\n",
    "    svc = SVC()\n",
    "    svc.fit(X_train, y_train)\n",
    "    acc_svc = svc.score(X_test, y_test) * 100\n",
    "\n",
    "    knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "    knn.fit(X_train, y_train)\n",
    "    acc_knn = knn.score(X_test, y_test) * 100\n",
    "\n",
    "    logreg = LogisticRegression()\n",
    "    logreg.fit(X_train, y_train)\n",
    "    acc_log = logreg.score(X_test, y_test) * 100\n",
    "\n",
    "\n",
    "\n",
    "    print(random_forest.feature_importances_)\n",
    "\n",
    "\n",
    "\n",
    "    sgd = SGDClassifier()\n",
    "    sgd.fit(X_train, y_train)\n",
    "    acc_sgd = round(sgd.score(X_test, y_test) * 100, 2)\n",
    "\n",
    "    gbc = GradientBoostingClassifier()\n",
    "    gbc.fit(X_train, y_train)\n",
    "    acc_gbc = round(gbc.score(X_test, y_test) * 100, 2)\n",
    "\n",
    "    models = pd.DataFrame({\n",
    "    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression',\n",
    "              'Random Forest', 'SGD' ,'GBC'],\n",
    "    'Score': [acc_svc, acc_knn, acc_log,\n",
    "              acc_random_forest, acc_sgd, acc_gbc]})\n",
    "\n",
    "    models.sort_values(by='Score', ascending=False)\n",
    "\n",
    "\n",
    "    print(models)\n",
    "    #\n",
    "    #\n",
    "    # # C=[0.05,0.1,0.2,0.3,0.25,0.4,0.5,0.6,0.7,0.8,0.9,1]\n",
    "    # # gamma=[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]\n",
    "    # # kernel=['rbf','linear']\n",
    "    # # hyper={'kernel':kernel,'C':C,'gamma':gamma}\n",
    "    # # gd=GridSearchCV(estimator=SVC(),param_grid=hyper,verbose=True)\n",
    "    # # gd.fit(X_train,y_train)\n",
    "    # # print(gd.best_score_)\n",
    "    # # print(gd.best_estimator_)\n",
    "    # # print(train_df.groupby(['COLLEGE','LEAVE'])['LEAVE'].count())\n",
    "\n",
    "\n",
    "    # predictions = random_forest.predict(test_df)\n",
    "    #\n",
    "    # fh = open(\"test_custom.csv\" , \"w\")\n",
    "    # lines_of_text = [\"ID,LEAVE\\n\"]\n",
    "    # index = 0\n",
    "    # for i in np.nditer(predictions.T, order='C'):\n",
    "    #     lines_of_text.append(str(index) + \",\" + str(i) + \"\\n\")\n",
    "    #     index += 1;\n",
    "    # fh.writelines(lines_of_text)\n",
    "    # fh.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
